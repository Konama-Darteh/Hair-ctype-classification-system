# -*- coding: utf-8 -*-
"""RestNet Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C1J5neqJRVQ067j7ZY9m4lB73YnvX7As
"""

# For saving the model
import pickle
from google.colab import drive
drive.mount('/content/drive')

import os, torch, random, numpy as np, pandas as pd
from glob import glob
from PIL import Image
from torch.utils.data import random_split, Dataset, DataLoader
from torchvision import transforms as T

torch.manual_seed(2024)

# --------------------------- Custom Dataset Class ---------------------------
class CustomDataset(Dataset):
    def __init__(self, root, transformations=None):
        self.transformations = transformations

        # ‚úÖ Load all supported image formats
        self.im_paths = glob(f"{root}/*/*.jpg") + glob(f"{root}/*/*.jpeg") + glob(f"{root}/*/*.png")
        print(f"üì∑ Found {len(self.im_paths)} images in total")

        self.cls_names, self.cls_counts, count = {}, {}, 0
        for im_path in self.im_paths:
            cls_name = self.get_cls_name(im_path)
            if cls_name not in self.cls_names:
                self.cls_names[cls_name] = count
                count += 1
            self.cls_counts[cls_name] = self.cls_counts.get(cls_name, 0) + 1

    def get_cls_name(self, path):
        return os.path.basename(os.path.dirname(path))  # folder name as class label

    def __len__(self):
        return len(self.im_paths)

    def get_pos_neg_im_paths(self, qry_label):
        pos_im_paths = [im_path for im_path in self.im_paths if qry_label == self.get_cls_name(im_path)]
        neg_im_paths = [im_path for im_path in self.im_paths if qry_label != self.get_cls_name(im_path)]

        pos_rand_int = random.randint(0, len(pos_im_paths) - 1)
        neg_rand_int = random.randint(0, len(neg_im_paths) - 1)

        return pos_im_paths[pos_rand_int], neg_im_paths[neg_rand_int]

    def __getitem__(self, idx):
        im_path = self.im_paths[idx]
        qry_im = Image.open(im_path).convert("RGB")
        qry_label = self.get_cls_name(im_path)

        pos_im_path, neg_im_path = self.get_pos_neg_im_paths(qry_label)
        pos_im = Image.open(pos_im_path).convert("RGB")
        neg_im = Image.open(neg_im_path).convert("RGB")

        qry_gt = self.cls_names[qry_label]
        neg_gt = self.cls_names[self.get_cls_name(neg_im_path)]

        if self.transformations is not None:
            qry_im = self.transformations(qry_im)
            pos_im = self.transformations(pos_im)
            neg_im = self.transformations(neg_im)

        return {
            "qry_im": qry_im,
            "qry_gt": qry_gt,
            "pos_im": pos_im,
            "neg_im": neg_im,
            "neg_gt": neg_gt
        }

# --------------------------- DataLoader Function ---------------------------
def get_dls(root, transformations, bs, split=[0.9, 0.05, 0.05], ns=0):
    ds = CustomDataset(root=root, transformations=transformations)
    total_len = len(ds)

    if total_len == 0:
        raise ValueError("üö® Dataset is empty! Check your image directory structure.")

    tr_len = int(total_len * split[0])
    vl_len = int(total_len * split[1])
    ts_len = total_len - (tr_len + vl_len)

    tr_ds, vl_ds, ts_ds = random_split(ds, [tr_len, vl_len, ts_len])

    tr_dl = DataLoader(tr_ds, batch_size=bs, shuffle=True, num_workers=ns)
    val_dl = DataLoader(vl_ds, batch_size=bs, shuffle=False, num_workers=ns)
    ts_dl = DataLoader(ts_ds, batch_size=1, shuffle=False, num_workers=ns)

    return tr_dl, val_dl, ts_dl, ds.cls_names, ds.cls_counts

# --------------------------- Parameters ---------------------------
root = "/content/drive/MyDrive/Figaro-1k/Original"
mean, std, size, bs = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225], 224, 32

tfs = T.Compose([
    T.ToTensor(),
    T.Resize(size=(size, size), antialias=True),
    T.Normalize(mean=mean, std=std)
    T.RandomHorizontalFlip(),
    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    T.RandomRotation(degrees=15),

])

# --------------------------- Load Data ---------------------------
tr_dl, val_dl, ts_dl, classes, cls_counts = get_dls(root=root, transformations=tfs, bs=bs)

# --------------------------- Inspect Results ---------------------------
print("\nüìä Training batches:", len(tr_dl))
print("üìä Validation batches:", len(val_dl))
print("üìä Test batches:", len(ts_dl))
print("üßæ Class mapping:", classes)

# ‚úÖ Show class image counts
print("\n‚úÖ Updated class counts:")
for cls, count in cls_counts.items():
    print(f"  - {cls}: {count} images")

"""import os, torch, random, shutil, numpy as np, pandas as pd
from glob import glob
from PIL import Image
from torch.utils.data import random_split, Dataset, DataLoader
from torchvision import transforms as T

torch.manual_seed(2024)

class CustomDataset(Dataset):
    def __init__(self, root, transformations=None):
        self.transformations = transformations

        # ‚úÖ Adjusted to match typical folder structure: root/ClassName/*.jpg
        self.im_paths = glob(f"{root}/*/*.jpg")
        print(f"üì∑ Found {len(self.im_paths)} images in total")

        self.cls_names, self.cls_counts, count = {}, {}, 0
        for idx, im_path in enumerate(self.im_paths):
            cls_name = self.get_cls_name(im_path)
            if cls_name not in self.cls_names:
                self.cls_names[cls_name] = count
                count += 1
            self.cls_counts[cls_name] = self.cls_counts.get(cls_name, 0) + 1

    def get_cls_name(self, path):
        return os.path.dirname(path).split("/")[-1]

    def __len__(self):
        return len(self.im_paths)

    def get_pos_neg_im_paths(self, qry_label):
        pos_im_paths = [im_path for im_path in self.im_paths if qry_label == self.get_cls_name(im_path)]
        neg_im_paths = [im_path for im_path in self.im_paths if qry_label != self.get_cls_name(im_path)]

        pos_rand_int = random.randint(0, len(pos_im_paths) - 1)
        neg_rand_int = random.randint(0, len(neg_im_paths) - 1)

        return pos_im_paths[pos_rand_int], neg_im_paths[neg_rand_int]

    def __getitem__(self, idx):
        im_path = self.im_paths[idx]
        qry_im = Image.open(im_path).convert("RGB")
        qry_label = self.get_cls_name(im_path)

        pos_im_path, neg_im_path = self.get_pos_neg_im_paths(qry_label)
        pos_im = Image.open(pos_im_path).convert("RGB")
        neg_im = Image.open(neg_im_path).convert("RGB")

        qry_gt = self.cls_names[qry_label]
        neg_gt = self.cls_names[self.get_cls_name(neg_im_path)]

        if self.transformations is not None:
            qry_im = self.transformations(qry_im)
            pos_im = self.transformations(pos_im)
            neg_im = self.transformations(neg_im)

        data = {
            "qry_im": qry_im,
            "qry_gt": qry_gt,
            "pos_im": pos_im,
            "neg_im": neg_im,
            "neg_gt": neg_gt
        }

        return data

def get_dls(root, transformations, bs, split=[0.9, 0.05, 0.05], ns=4):
    ds = CustomDataset(root=root, transformations=transformations)
    total_len = len(ds)

    if total_len == 0:
        raise ValueError("üö® Dataset is empty! Check your image directory structure.")

    tr_len = int(total_len * split[0])
    vl_len = int(total_len * split[1])
    ts_len = total_len - (tr_len + vl_len)

    tr_ds, vl_ds, ts_ds = random_split(ds, [tr_len, vl_len, ts_len])


    tr_dl = DataLoader(tr_ds, batch_size=bs, shuffle=True, num_workers=0)
    val_dl = DataLoader(vl_ds, batch_size=bs, shuffle=False, num_workers=0)
    ts_dl = DataLoader(ts_ds, batch_size=1, shuffle=False, num_workers=0)

    return tr_dl, val_dl, ts_dl, ds.cls_names, ds.cls_counts

# üß† Parameters
root = "/content/drive/MyDrive/Figaro-1k/Original"
mean, std, size, bs = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225], 224, 32

# üé® Transforms
tfs = T.Compose([
    T.ToTensor(),
    T.Resize(size=(size, size), antialias=True),
    T.Normalize(mean=mean, std=std)
])

# üß™ Load DataLoaders
tr_dl, val_dl, ts_dl, classes, cls_counts = get_dls(root=root, transformations=tfs, bs=bs)

# üîç Inspect
print("üìä Training batches:", len(tr_dl))
print("üìä Validation batches:", len(val_dl))
print("üìä Test batches:", len(ts_dl))
print("üßæ Classes:", classes)

DATA ANALYSIS
"""

import numpy as np
from matplotlib import pyplot as plt
from torchvision import transforms as T

class Visualization:

    def __init__(self, vis_datas, n_ims, rows, cmap = None, cls_names = None, cls_counts = None, t_type = "rgb"):

        self.n_ims, self.rows = n_ims, rows
        self.t_type, self.cmap,  = t_type, cmap
        self.cls_names = cls_names

        self.vis_datas = {"train": vis_datas[0], "val": vis_datas[1], "test": vis_datas[2]}
        if isinstance(cls_counts, list) and len(cls_counts) == 2: self.analysis_datas = {"train": cls_counts[0], "test": cls_counts[1]}
        elif isinstance(cls_counts, list) and len(cls_counts) == 3: self.analysis_datas = {"train": cls_counts[0], "val": cls_counts[1], "test": cls_counts[2]}
        else: self.analysis_datas = {"all": cls_counts}

    def tn2np(self, t):

        gray_tfs = T.Compose([T.Normalize(mean = [ 0.], std = [1/0.5]), T.Normalize(mean = [-0.5], std = [1])])
        rgb_tfs = T.Compose([T.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.229, 1/0.224, 1/0.225 ]), T.Normalize(mean = [ -0.485, -0.456, -0.406 ], std = [ 1., 1., 1. ])])

        invTrans = gray_tfs if self.t_type == "gray" else rgb_tfs

        return (invTrans(t) * 255).detach().squeeze().cpu().permute(1,2,0).numpy().astype(np.uint8) if self.t_type == "gray" else (invTrans(t) * 255).detach().cpu().permute(1,2,0).numpy().astype(np.uint8)

    def plot(self, rows, cols, count, im, title = "Original Image"):

        plt.subplot(rows, cols, count)
        plt.imshow(self.tn2np(im))
        plt.axis("off"); plt.title(title)

        return count + 1

    def vis(self, data, save_name):

        print(f"{save_name.upper()} Data Visualization is in process...\n")
        assert self.cmap in ["rgb", "gray"], "Please choose rgb or gray cmap"
        if self.cmap == "rgb": cmap = "viridis"
        cols = self.n_ims // self.rows; count = 1

        plt.figure(figsize = (25, 20))

        indices = [np.random.randint(low = 0, high = len(data) - 1) for _ in range(self.n_ims)]

        for idx, index in enumerate(indices):

            if count == self.n_ims + 1: break

            meta_data = data[index]
            qry_im, pos_im, neg_im, qry_lbl, neg_lbl = meta_data["qry_im"], meta_data["pos_im"], meta_data["neg_im"], meta_data["qry_gt"], meta_data["neg_gt"]

            # First Plot
            count = self.plot(self.rows, cols, count, im = qry_im, title = f"Query Image \n Class -> {self.cls_names[qry_lbl]}")

            # Second Plot
            count = self.plot(self.rows, cols, count, im = pos_im, title = f"Positive Image \n Class -> {self.cls_names[qry_lbl]}")

            # Third Plot
            count = self.plot(self.rows, cols, count, im = neg_im, title = f"Negative Image \n Class -> {self.cls_names[neg_lbl]}")

        plt.title(f"{save_name.upper()} Dataset Visualization"); plt.show()

    def data_analysis(self, cls_counts, save_name):

        print("Data analysis is in process...\n")

        width, text_width, text_height = 0.7, 0.05, 2
        cls_names = list(cls_counts.keys()); counts = list(cls_counts.values())

        _, ax = plt.subplots(figsize = (20, 10))
        indices = np.arange(len(counts))

        ax.bar(indices, counts, width, color = "firebrick")
        ax.set_xlabel("Class Names", color = "red")
        ax.set_xticklabels(cls_names, rotation = 60)
        ax.set(xticks = indices, xticklabels = cls_names)
        ax.set_ylabel("Data Counts", color = "red")
        ax.set_title(f"Dataset Class Imbalance Analysis")

        for i, v in enumerate(counts): ax.text(i - text_width, v + text_height, str(v), color = "royalblue")

    def visualization(self): [self.vis(data.dataset, save_name) for (save_name, data) in self.vis_datas.items()]

    def analysis(self): [self.data_analysis(data, save_name) for (save_name, data) in self.analysis_datas.items()]

vis = Visualization(vis_datas = [tr_dl, val_dl, ts_dl], n_ims = 18, rows = 6, cmap = "rgb", cls_names = list(classes.keys()), cls_counts = cls_counts)
vis.analysis()

"""DATA Visualization"""

vis.visualization()

"""Model Traning and Validation"""

!pip install torchmetrics

import os
import torch
import datetime
from tqdm import tqdm
from time import time
from torchmetrics.classification import MulticlassStatScores, MulticlassF1Score
import timm

class TrainValidation:

    def __init__(self, model_name, tr_dl, val_dl, classes, device, lr, save_dir,
                 run_name, data_name, epochs, project_name, bs, patience=5):

        self.model_name, self.classes, self.device = model_name, classes, device
        self.data_name, self.lr, self.save_dir, self.bs = data_name, lr, save_dir, bs
        self.tr_dl, self.val_dl, self.patience = tr_dl, val_dl, patience
        self.run_name, self.epochs, self.project_name = run_name, epochs, project_name
        self.run()

    def init_model(self):
         self.model = timm.create_model("resnet18", pretrained=True, num_classes=num_classes, drop_rate=0.5)
        #self.model = timm.create_model(self.model_name, pretrained=True, num_classes=len(self.classes))

    def init_lists(self):
        self.tr_losses, self.val_losses = [], []
        self.tr_accs, self.val_accs = [], []
        self.tr_f1s, self.val_f1s = [], []
        self.tr_specs, self.val_specs = [], []
        self.tr_sens, self.val_senss = [], []
        self.tr_times, self.vl_times = [], []

    def train_setup(self):
        self.best_loss, self.threshold, self.not_improved = float(torch.inf), 0.01, 0
        self.stop_train, self.tr_len, self.val_len = False, len(self.tr_dl), len(self.val_dl)
        self.ckpt_path = f"{self.save_dir}/{self.data_name}_{self.run_name}_{self.model_name}_best_model.pth"

        self.model.to(self.device).eval()
        self.ce_loss_fn = torch.nn.CrossEntropyLoss()
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4, weight_decay=1e-5)
       # self.optimizer = torch.optim.Adam(params=self.model.parameters(), lr=self.lr)
        self.f1_score = MulticlassF1Score(num_classes=len(self.classes), average="micro").to(self.device)
        self.stat_scores = MulticlassStatScores(num_classes=len(self.classes), average="micro").to(self.device)

    def makedirs(self, path):
        os.makedirs(path, exist_ok=True)

    def train_one_epoch(self, epoch):
        self.model.train()
        epoch_loss, epoch_acc, epoch_f1, spec, sens = 0, 0, 0, 0, 0

        tr_start = time()
        for batch in tqdm(self.tr_dl):
            ims, lbls = batch["qry_im"].to(self.device), batch["qry_gt"].to(self.device)
            preds = self.model(ims)

            loss = self.ce_loss_fn(preds, lbls)
            self.optimizer.zero_grad(); loss.backward(); self.optimizer.step()

            epoch_loss += loss.item()
            epoch_acc += (preds.argmax(dim=1) == lbls).sum().item()
            epoch_f1 += self.f1_score(preds.argmax(dim=1), lbls)
            tp, fp, tn, fn, _ = self.stat_scores(preds.argmax(dim=1), lbls)
            spec += tn / (tn + fp)
            sens += tp / (tp + fn)

        tr_time = time() - tr_start
        self.tr_times.append(tr_time)

        self.tr_losses.append(epoch_loss / self.tr_len)
        self.tr_accs.append(epoch_acc / len(self.tr_dl.dataset))
        self.tr_f1s.append(epoch_f1 / self.tr_len)
        self.tr_specs.append(spec / self.tr_len)
        self.tr_sens.append(sens / self.tr_len)

    def eval_one_epoch(self, epoch):
        self.model.eval()
        val_loss, val_acc, val_f1, val_spec, val_sens = 0, 0, 0, 0, 0

        with torch.no_grad():
            val_start = time()
            for batch in self.val_dl:
                ims, lbls = batch["qry_im"].to(self.device), batch["qry_gt"].to(self.device)
                preds = self.model(ims)
                loss = self.ce_loss_fn(preds, lbls)

                val_loss += loss.item()
                val_acc += (preds.argmax(dim=1) == lbls).sum().item()
                val_f1 += self.f1_score(preds.argmax(dim=1), lbls)
                tp, fp, tn, fn, _ = self.stat_scores(preds.argmax(dim=1), lbls)
                val_spec += tn / (tn + fp)
                val_sens += tp / (tp + fn)

            val_time = time() - val_start
            self.vl_times.append(val_time)

            self.val_losses.append(val_loss / self.val_len)
            self.val_accs.append(val_acc / len(self.val_dl.dataset))
            self.val_f1s.append(val_f1 / self.val_len)
            self.val_specs.append(val_spec / self.val_len)
            self.val_senss.append(val_sens / self.val_len)

        return self.val_losses[-1]

    def save_best_model(self):
      # Save the entire model instead of just state_dict
      self.ckpt_path = self.ckpt_path.replace(".pth", "_full_model.pt")
      torch.save(self.model, self.ckpt_path)
      print("‚úÖ Full model saved using torch.save()!")


    def epoch_summary(self, metric):
        if (metric + self.threshold) < self.best_loss:
            self.best_loss = metric
            self.save_best_model()
            self.not_improved = 0
        else:
            self.not_improved += 1
            if self.not_improved >= self.patience:
                self.stop_train = True

    def train(self):
        print("üöÄ Training started...")
        for epoch in range(self.epochs):
            self.train_one_epoch(epoch)
            val_loss = self.eval_one_epoch(epoch)
            self.epoch_summary(val_loss)
            if self.stop_train:
                print("‚õî Early stopping triggered.")
                break

    def get_stats(self):
        return [self.tr_losses, self.val_losses, self.tr_accs, self.val_accs,
                self.tr_f1s, self.val_f1s, self.tr_specs, self.val_specs,
                self.tr_sens, self.val_senss, self.tr_times, self.vl_times]

    def run(self):
        self.makedirs(self.save_dir)
        self.init_lists()
        self.init_model()
        self.train_setup()
        self.train()

# ‚úÖ CONFIGURATION
project_name = "hair_classification"
run_name = "triplet_run"
model_name = "resnet18"
save_dir = "/content/drive/MyDrive/hair_classification_models"
data_name = "hair_data"
epochs = 10
device = "cuda" if torch.cuda.is_available() else "cpu"

num_classes = len(classes)

# ‚úÖ TRAIN & VALIDATE
results = TrainValidation(
    model_name=model_name,
    tr_dl=tr_dl,
    val_dl=val_dl,
    classes=classes,
    device=device,
    lr=3e-4,
    save_dir=save_dir,
    data_name=data_name,
    project_name=project_name,
    bs=bs,
    run_name=run_name,
    epochs=epochs,
    patience=5
).get_stats()

#confusion metrix
''''import torch
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

all_preds = []
all_labels = []

model.eval()  # make sure to use your loaded model
with torch.no_grad():
    for batch in ts_dl:
        ims = batch["qry_im"].to(device)
        lbls = batch["qry_gt"].to(device)

        outputs = model(ims)
        preds = torch.argmax(outputs, dim=1)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(lbls.cpu().numpy())

# Generate confusion matrix
cm = confusion_matrix(all_labels, all_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(classes.keys()))
disp.plot(cmap="Blues", xticks_rotation=45)
plt.title("Confusion Matrix")
plt.show()'''

"""LEARNING CURVE"""

from matplotlib import pyplot as plt
import numpy as np
import os

class TrainProcessSummary:

    def __init__(self, tr_losses, val_losses, tr_accs, val_accs, tr_f1s,
                 val_f1s, tr_specs, val_spec, tr_sens, val_sens, tr_times,
                 vl_times, data_name, save_path="learning_curves"):

        self.makedirs(save_path)
        self.xlbl = "Epochs"
        self.times_sv_name = "times.png"
        self.data_name = data_name
        self.save_path = save_path

        self.tr_losses = tr_losses
        self.val_losses = val_losses
        self.tr_accs = tr_accs
        self.val_accs = val_accs
        self.tr_f1s = tr_f1s
        self.val_f1s = val_f1s
        self.tr_specs = tr_specs
        self.val_spec = val_spec
        self.tr_sens = tr_sens
        self.val_sens = val_sens
        self.tr_times = tr_times
        self.vl_times = vl_times

        self.get_ticks_labels()
        self.learning_curves()
        self.bar_plot()

        print(f"‚úÖ Learning curves saved to: {self.save_path}")
        print(f"‚è±Ô∏è  Train/Validation time bar chart: {self.times_sv_name}")

    def get_ticks_labels(self):
        self.xtics = np.arange(len(self.tr_losses))
        self.xlabels = [i for i in range(1, len(self.tr_losses) + 1)]

    def makedirs(self, path):
        os.makedirs(path, exist_ok=True)

    def create_figure(self):
        plt.figure(figsize=(10, 5))

    def move2cpu(self, data):
        return [d.cpu() if hasattr(d, "cpu") else d for d in data]

    def plot(self, data1, data2, plot_name, c1, c2):
        self.create_figure()
        if plot_name in ["Sensitivity", "Specificity", "F1"]:
            data1 = self.move2cpu(data1)
            data2 = self.move2cpu(data2)

        label = f"{plot_name} Scores"
        plt.plot(data1, label=f"Train {label}", color=c1)
        plt.plot(data2, label=f"Validation {label}", color=c2)
        plt.xlabel(self.xlbl)
        plt.ylabel(label)
        plt.title(f"{plot_name} - Train vs Validation")
        plt.xticks(ticks=self.xtics, labels=self.xlabels)
        plt.legend()
        self.save(f"{plot_name.lower()}.png")
        plt.show()

    def save(self, save_name):
        sv_name = f"{self.data_name}_{save_name}"
        plt.savefig(f"{self.save_path}/{sv_name}")

    def learning_curves(self):
        self.plot(self.tr_losses, self.val_losses, "Loss", "red", "blue")
        self.plot(self.tr_accs, self.val_accs, "Accuracy", "orange", "green")
        self.plot(self.tr_f1s, self.val_f1s, "F1", "cyan", "lime")
        self.plot(self.tr_specs, self.val_spec, "Specificity", "violet", "dodgerblue")
        self.plot(self.tr_sens, self.val_sens, "Sensitivity", "gold", "lightcoral")

    def bar_plot(self):
        self.create_figure()
        plt.bar(self.xtics - 0.2, self.tr_times, 0.4, label="Train")
        plt.bar(self.xtics + 0.2, self.vl_times, 0.4, label="Validation")
        plt.xticks(self.xtics)
        plt.xlabel(self.xlbl)
        plt.ylabel("Seconds")
        plt.title("Train and Validation Times")
        plt.legend()
        self.save(self.times_sv_name)
        plt.show()

# Run this after training
TrainProcessSummary(*results, data_name=data_name)

!pip install grad-cam

"""‚úÖ 6. Inference and AI Model Performance Analysis with GradCAM ‚úÖ"""

import os
import torch
import random
import matplotlib.pyplot as plt
from tqdm import tqdm
from time import time
from torchvision import transforms as T
from torchmetrics.classification import MulticlassStatScores
from pytorch_grad_cam import GradCAMPlusPlus
from pytorch_grad_cam.utils.image import show_cam_on_image
import timm

class Inference:

    def __init__(self, model_name, device, ckpt_path, save_path, test_dl, save_name, cls_names, grad_cam=False, num_ims=12):
        self.model_name = model_name
        self.device = device
        self.ckpt_path = ckpt_path
        self.save_path = save_path
        self.test_dl = test_dl
        self.save_name = save_name
        self.cls_names = cls_names
        self.num_ims = num_ims
        self.grad_cam = grad_cam

    def makedirs(self, path):
        os.makedirs(path, exist_ok=True)

    def load_model(self):
        self.model = timm.create_model(self.model_name, pretrained=False, num_classes=len(self.cls_names))
        self.model.load_state_dict(torch.load(self.ckpt_path, map_location=self.device))
        self.model.eval()
        return self.model.to(self.device)

    def to_device(self, batch):
        return batch["qry_im"].to(self.device), batch["qry_gt"].to(self.device)

    def tn2np(self, t):
        inv_normalize = T.Compose([
            T.Normalize(mean=[0., 0., 0.], std=[1/0.229, 1/0.224, 1/0.225]),
            T.Normalize(mean=[-0.485, -0.456, -0.406], std=[1., 1., 1.])
        ])
        np_img = inv_normalize(t).clamp(0, 1).permute(1, 2, 0).cpu().numpy()
        return np_img

    def inference(self):
        self.makedirs(self.save_path)
        self.load_model()

        stat_scores = MulticlassStatScores(num_classes=len(self.cls_names), average="micro").to(self.device)
        tps, fps, tns, fns = 0, 0, 0, 0
        preds, images, lbls = [], [], []

        start_time = time()
        for batch in tqdm(self.test_dl):
            ims, gts = self.to_device(batch)
            pred_classes = torch.argmax(self.model(ims), dim=1)

            tp, fp, tn, fn, _ = stat_scores(pred_classes, gts)
            tps += tp
            fps += fp
            tns += tn
            fns += fn

            images.append(ims[0])
            preds.append(pred_classes[0])
            lbls.append(gts[0])

        specificity = tns / (tns + fps)
        sensitivity = tps / (tps + fns)

        print(f"\n‚úÖ Inference completed in {(time() - start_time):.2f} seconds")
        print(f"Sensitivity: {sensitivity:.3f}")
        print(f"Specificity: {specificity:.3f}")

        # üñºÔ∏è Visualization
        print("\nüñºÔ∏è Visualizing predictions...\n")
        plt.figure(figsize=(20, 10))
        cols = 4
        rows = (self.num_ims + cols - 1) // cols
        selected_indices = random.sample(range(len(images)), min(self.num_ims, len(images)))

        for idx, index in enumerate(selected_indices):
            im = images[index]
            np_im = self.tn2np(im)

            plt.subplot(rows, cols, idx + 1)
            if self.grad_cam:
                cam = GradCAMPlusPlus(model=self.model, target_layers=[self.model.get_classifier()], use_cuda=(self.device == "cuda"))
                grayscale_cam = cam(input_tensor=im.unsqueeze(0))[0]
                visualization = show_cam_on_image(np_im, grayscale_cam, use_rgb=True)
                plt.imshow(visualization)
            else:
                plt.imshow(np_im)

            true_cls = list(self.cls_names.keys())[int(lbls[index])]
            pred_cls = list(self.cls_names.keys())[int(preds[index])]
            color = "green" if true_cls == pred_cls else "red"
            plt.title(f"GT: {true_cls} | Pred: {pred_cls}", color=color)
            plt.axis("off")

        plt.tight_layout()
        save_img_path = f"{self.save_path}/{self.save_name}_results.png"
        plt.savefig(save_img_path)
        print(f"\nüìÅ Visualization saved to: {save_img_path}\n")
        plt.show()

    def run(self):
        self.inference()

import os

model_path = f"{save_dir}/{data_name}_{run_name}_{model_name}_best_model_full_model.pt"
print(f"üîç Checking for model at: {model_path}")
print("‚úÖ Path exists!" if os.path.exists(model_path) else "‚ùå Path NOT found!")

Inference(
    model_name=model_name,
    device=device,
    ckpt_path=model_path,
    save_path="results",
    test_dl=ts_dl,
    save_name="inference_vis",
    cls_names=classes,
    grad_cam=False,
    num_ims=12
).run()